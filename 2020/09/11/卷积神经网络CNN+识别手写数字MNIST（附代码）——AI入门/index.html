<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>卷积神经网络(CNN)识别手写数字MNIST(附代码) | Ana's blog</title><meta name="keywords" content="network,python"><meta name="author" content="Anastasia"><meta name="copyright" content="Anastasia"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="写在前面  此文是我学习AI入门的笔记。学习教材《neural networks and deep learning》，作者Michael Nielsen。 这是一本免费的书籍，网址在这里。 此文是第六章内容的学习总结，前几章的内容总结可以见我的博客。 初学者入门，如有错误，请指正。   简介卷积神经网络 在之前的学习中，我们都是使用全连接的神经网络来处理问题的。即，⽹络中的神经元与相邻的层上的每">
<meta property="og:type" content="article">
<meta property="og:title" content="卷积神经网络(CNN)识别手写数字MNIST(附代码)">
<meta property="og:url" content="http://example.com/2020/09/11/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN+%E8%AF%86%E5%88%AB%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97MNIST%EF%BC%88%E9%99%84%E4%BB%A3%E7%A0%81%EF%BC%89%E2%80%94%E2%80%94AI%E5%85%A5%E9%97%A8/index.html">
<meta property="og:site_name" content="Ana&#39;s blog">
<meta property="og:description" content="写在前面  此文是我学习AI入门的笔记。学习教材《neural networks and deep learning》，作者Michael Nielsen。 这是一本免费的书籍，网址在这里。 此文是第六章内容的学习总结，前几章的内容总结可以见我的博客。 初学者入门，如有错误，请指正。   简介卷积神经网络 在之前的学习中，我们都是使用全连接的神经网络来处理问题的。即，⽹络中的神经元与相邻的层上的每">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-fc6b5bc5ed17621fa52acf7a19b2e379_1440w.jpg">
<meta property="article:published_time" content="2020-09-11T08:36:00.000Z">
<meta property="article:modified_time" content="2021-06-07T01:37:18.996Z">
<meta property="article:author" content="Anastasia">
<meta property="article:tag" content="network">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-fc6b5bc5ed17621fa52acf7a19b2e379_1440w.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2020/09/11/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN+%E8%AF%86%E5%88%AB%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97MNIST%EF%BC%88%E9%99%84%E4%BB%A3%E7%A0%81%EF%BC%89%E2%80%94%E2%80%94AI%E5%85%A5%E9%97%A8/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.1.1',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-06-07 09:37:18'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.1.1"><link rel="alternate" href="/atom.xml" title="Ana's blog" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">16</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">7</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">4</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">简介卷积神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%B1%80%E9%83%A8%E6%84%9F%E5%8F%97%E9%87%8E"><span class="toc-number">2.1.</span> <span class="toc-text">1. 局部感受野</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%85%B1%E4%BA%AB%E6%9D%83%E9%87%8D%E5%92%8C%E5%81%8F%E7%BD%AE"><span class="toc-number">2.2.</span> <span class="toc-text">2. 共享权重和偏置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E6%B1%A0%E5%8C%96"><span class="toc-number">2.3.</span> <span class="toc-text">3. 池化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%80%E5%A4%A7%E5%80%BC%E6%B1%A0%E5%8C%96%EF%BC%88max-pooling%EF%BC%89"><span class="toc-number">2.3.1.</span> <span class="toc-text">最大值池化（max-pooling）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#L2%E6%B1%A0%E5%8C%96%EF%BC%88L2-pooling%EF%BC%89"><span class="toc-number">2.3.2.</span> <span class="toc-text">L2池化（L2-pooling）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%BC%E5%90%88"><span class="toc-number">2.4.</span> <span class="toc-text">综合</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">代码</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE"><span class="toc-number">3.1.</span> <span class="toc-text">环境配置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%A5%E9%94%99%E5%A4%84%E7%90%86"><span class="toc-number">3.2.</span> <span class="toc-text">报错处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E8%BF%90%E8%A1%8C"><span class="toc-number">3.3.</span> <span class="toc-text">代码运行</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="toc-number">3.3.1.</span> <span class="toc-text">一层卷积网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%A4%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C"><span class="toc-number">3.3.2.</span> <span class="toc-text">两层卷积网络</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%AE%E6%AD%A3%E7%BA%BF%E6%80%A7%E5%8D%95%E5%85%83"><span class="toc-number">3.3.3.</span> <span class="toc-text">修正线性单元</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8B%93%E5%B1%95%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="toc-number">3.3.4.</span> <span class="toc-text">拓展训练数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%BC%83%E6%9D%83%E7%9A%84%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82"><span class="toc-number">3.3.5.</span> <span class="toc-text">使用弃权的全连接层</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E7%BB%84%E5%90%88%E7%BD%91%E7%BB%9C"><span class="toc-number">3.3.6.</span> <span class="toc-text">使用组合网络</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%BA%90%E4%BB%A3%E7%A0%81"><span class="toc-number">3.4.</span> <span class="toc-text">源代码</span></a></li></ol></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-fc6b5bc5ed17621fa52acf7a19b2e379_1440w.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Ana's blog</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">卷积神经网络(CNN)识别手写数字MNIST(附代码)</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-09-11T08:36:00.000Z" title="发表于 2020-09-11 16:36:00">2020-09-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-06-07T01:37:18.996Z" title="更新于 2021-06-07 09:37:18">2021-06-07</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/network/">network</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>24分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1>写在前面</h1>
<ol>
<li>此文是我学习AI入门的笔记。学习教材《neural networks and deep learning》，作者Michael Nielsen。</li>
<li>这是一本免费的书籍，网址<a target="_blank" rel="noopener" href="http://neuralnetworksanddeeplearning.com/chap6.html">在这里</a>。</li>
<li>此文是<strong>第六章</strong>内容的学习总结，前几章的内容总结可以见<a target="_blank" rel="noopener" href="https://anastasiawangyx.github.io/">我的博客</a>。</li>
<li>初学者入门，如有错误，请指正。</li>
</ol>
<blockquote></blockquote>
<h1>简介卷积神经网络</h1>
<p>在之前的学习中，我们都是使用<strong>全连接</strong>的神经网络来处理问题的。即，⽹络中的神经元与相邻的层上的每个神经元均连接，在此之前我们已经获得了98%的分辨率了。<br>
<img src="https://img-blog.csdnimg.cn/20200123131431465.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
但是在识别手写数字的问题上，这样连接方式有很大的缺点：</p>
<p>它忽略了图像本身的<strong>空间结构（spatial structure）</strong>，而以同样的方式对待所有的输入像素。</p>
<p>今天介绍的卷积神经网络则可以很好的利用图像的空间结构，是处理图像分类问题的一个很好的框架。</p>
<p>学习CNN框架，就要了解它的三个基本概念：</p>
<ul>
<li>Local receptive fields 局部感受野</li>
<li>shared weights 共享权重</li>
<li>pooling  池化</li>
</ul>
<h2 id="1-局部感受野">1. 局部感受野</h2>
<p>在识别手写数字的问题中，输入层是28 * 28的图像的像素灰度，因此输入层共有28 * 28=784个神经元。</p>
<p>在CNN中，我们将这784个神经元看做方形排列。</p>
<p><img src="https://img-blog.csdnimg.cn/20200123132827447.png" alt="在这里插入图片描述"></p>
<p>当我们把输入层神经元连接到隐藏神经元层时，我们不会全部映射，而是进行小的、局部的连接。</p>
<p>例如，我们将输入层一个5 * 5的方形区域连接到隐藏层的一个神经元。</p>
<p><img src="https://img-blog.csdnimg.cn/20200123133247141.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
这个输⼊图像的区域被称为隐藏神经元的<strong>局部感受野</strong>。它是输入像素上的一个小窗口。每个连接学习⼀个权重。而隐藏神经元同时也学习⼀个总的偏置。你可以把这个特定的隐藏神经元看作是在学习分析它的局部感受野。</p>
<p>然后我们在输入层上移动局部感受野，而每一个不同的局部感受野对应了隐藏层上的一个神经元。</p>
<p>例如，输入层左上角的25个神经元对应第一个隐藏神经元。</p>
<p><img src="https://img-blog.csdnimg.cn/20200123133628651.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>然后我们向右移动一个像素（神经元），对应隐藏层第二个神经元。</p>
<p><img src="https://img-blog.csdnimg.cn/20200123133736448.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>如此不断移动，我们会得到一个24 * 24个神经元的隐藏层。</p>
<p>当然我们也可以使用不同的<strong>跨距</strong>（stride length），比如一次移动两个像素。在此处我们取跨距为1。</p>
<h2 id="2-共享权重和偏置">2. 共享权重和偏置</h2>
<p>对于每一个隐藏层神经元，它具有一个偏置，并连接了一个5 * 5的局部感受野，所以也有5 * 5个权重。</p>
<p>对于同一层的每一个隐藏神经元，我们使用<strong>相同的偏置和5* 5权重</strong>，换句话说，对于隐藏层的每一个神经元，其输出公式为<br>
<img src="https://img-blog.csdnimg.cn/20200123143230150.JPG" alt="在这里插入图片描述"></p>
<ul>
<li>σ是神经元的激活函数，可以是我们之前学习过的S型函数。</li>
<li>b是共享偏置</li>
<li>w~l,m~是一个共享的5 * 5 的权值数组</li>
<li>a~x,y~表示位于x，y位置的输入激活值</li>
</ul>
<p>对同一个隐藏层使用相同的权重和偏置，就可以让此层的神经元在图像的不同位置学习一个特定的特征。</p>
<p>也因此，我们将从输入层到隐藏层的映射称为<strong>特征映射（feature map）</strong><br>
将定义特征映射的权重和偏置称为<strong>共享权重（shared weights）和共享偏置（shared bias）</strong>，也称作<strong>卷积核（kernel）或滤波器（filter）</strong>，这是一些文献中可能会使用的术语。</p>
<p>⽬前我描述的⽹络结构只能检测⼀种局部特征的类型。为了完成图像识别我们需要超过⼀个的特征映射。所以⼀个完整的卷积层由几个不同的特征映射组成：<br>
<img src="https://img-blog.csdnimg.cn/20200123172115130.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>在上图所示的例子中，我们使用了三个特征映射，每个特征映射由一个5 * 5的权值数组和一个偏置，可以探测图像的一个特征。</p>
<p>而在下面我们的实际开发案例中，我们使用了20个特征映射（卷积核、滤波器），学习了下面的20种图形特征。</p>
<p>![在这里插入图片描述](<a target="_blank" rel="noopener" href="https://img-blog.csdnimg.cn/20200123173014806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70">https://img-blog.csdnimg.cn/20200123173014806.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70</a>  =490x430)</p>
<p>每个映射有⼀幅 5 × 5 块的图像表示，对应于局部感受野中的 5 × 5 权重。白色块意味着⼀个小（更小的负数）权重，所以这样的特征映射对相应的输⼊像素有更小的响应。更暗的块意味着⼀个更⼤的权重，所以这样的特征映射对相应的输⼊像素有更大的响应。</p>
<p>共享权重和偏置的⼀个很⼤的优点是，它⼤⼤<strong>减少了参与的卷积网络的参数</strong>。对于每个特征映射我们需要 25 = 5 × 5 个共享权重，加上⼀个共享偏置。所以每个特征映射需要 26 个参数。如果我们有 20 个特征映射，那么总共有 20 × 26 = 520 个参数来定义卷积层。</p>
<p>作为对比，假设我们有⼀个全连接的第⼀层，具有 784 = 28 × 28 个输⼊神经元，和⼀个相对适中的 30 个隐藏神经元，正如我们在本书之前的很多例⼦中使⽤的。总共有 784 × 30 个权重，加上额外的 30 个偏置，共有 23, 550 个参数。换句话说，这个全连接的层有多达 40 倍于卷基层的参数。</p>
<h2 id="3-池化">3. 池化</h2>
<p>卷积神经网络除了卷积层之外，还有池化层。池化层通常在卷积层之后，主要作用是简化从卷积层输出的信息。</p>
<h3 id="最大值池化（max-pooling）">最大值池化（max-pooling）</h3>
<p>最大值混合是一个常见的池化方式。一个池化单元将卷积层一个区域（例如2<br>
*2）中的<strong>最大激活值</strong>作为其输出：<br>
<img src="https://img-blog.csdnimg.cn/20200123192648729.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
注意既然从卷积层有 24 × 24 个神经元输出，混合后我们得到 12 × 12 个神经元。</p>
<p>正如上⾯提到的，卷积层通常包含超过⼀个特征映射。我们将最⼤值混合分别应⽤于每⼀个特征映射。所以如果有三个特征映射，组合在⼀起的卷积层和最⼤值混合层看起来像这样：</p>
<p><img src="https://img-blog.csdnimg.cn/2020012319313268.png" alt="在这里插入图片描述"><br>
通过池化的方式，网络可以得知，对于给定的一种图形特征，它大致分布在图像的哪些位置，而不需要处理大量具体的位置信息，这有助于减少在后面的层中所需的参数的数目。</p>
<h3 id="L2池化（L2-pooling）">L2池化（L2-pooling）</h3>
<p>L2-池化则是取 2×2 区域中<strong>激活值的平方和的平方根</strong>。</p>
<p>虽然细节不同，但是两种池化方式都被广泛应用到实际中。</p>
<h2 id="综合">综合</h2>
<p>我们现在可以把这些思想都放在⼀起来构建⼀个完整的卷积神经⽹络。它和我们刚看到的架构相似，但是有额外的⼀层 10 个输出神经元，对应于 10 个可能的 MNIST 数字（’0’，’1’，’2’ 等）：</p>
<p><img src="https://img-blog.csdnimg.cn/20200123194551914.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
这个⽹络从 28 × 28 个输⼊神经元开始，这些神经元⽤于对 MNIST 图像的像素强度进⾏编码。</p>
<p>接着的是⼀个卷积层，使⽤⼀个 5×5 局部感受野和 3 个特征映射。其结果是⼀个 3×24×24隐藏特征神经元层。下⼀步是⼀个最大值池化层，应⽤于 2 × 2 区域，遍及 3 个特征映射。结果是⼀个 3 × 12 × 12 隐藏特征神经元层。</p>
<p>网络中最后连接的层是⼀个<strong>全连接层</strong>。更确切地说，这⼀层将最⼤值混合层的每⼀个神经元连接到每⼀个输出神经元。这个全连接结构和我们之前章节中使用的相同。</p>
<blockquote></blockquote>
<h1>代码</h1>
<p>现在将卷积神经网络应用于手写数字MNIST问题。</p>
<h2 id="环境配置">环境配置</h2>
<p>此处提供代码的<a target="_blank" rel="noopener" href="https://github.com/mnielsen/neural-networks-and-deep-learning">Github下载地址</a>，我们此次运行的代码是<code><a target="_blank" rel="noopener" href="http://network3.py">network3.py</a></code>,是之前运行的<code><a target="_blank" rel="noopener" href="http://network.py">network.py</a></code>和<code><a target="_blank" rel="noopener" href="http://network2.py">network2.py</a></code>的加强版。</p>
<p>跟前面的章节相似，我们会使用Anaconda来运行作者的python2 的代码，同时需要<code>numpy</code>库和<code>Theano</code>库。</p>
<p>Anaconda和numpy库的下载及使用可以参考我之前的一篇博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/Anastasiawangyx/article/details/102649158">使用神经网络实现手写数字识别（MNIST）</a></p>
<p>我们还需要下载Theano库来运行代码。网上关于Theano的下载和安装教程不多，但是我基本都没怎么看懂（咳咳）。自己倒腾了一下不知道为啥就可以运行了（那就这样吧），此处放上<a target="_blank" rel="noopener" href="http://deeplearning.net/software/theano/">Theano的官方文档</a>供大家参考。</p>
<p>首先在Anaconda中进入自己的python2环境，我的环境名叫<code>deeplearning</code>.</p>
<p>输入<code>conda install theano</code>,下载theano包。<br>
<img src="https://img-blog.csdnimg.cn/20200123203927151.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
我因为已经安装过了所以显示是#All requested packages already installed</p>
<p>在我的电脑上安装时，会首先提示是否安装，输入<code>y</code>继续安装，接着等待5min左右就可以安装完成了。</p>
<p>完成后我们输入<code>conda list</code>查看<br>
<img src="https://img-blog.csdnimg.cn/20200123204329287.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
可以看到<code>theano</code>和<code>numpy</code>库，则安装成功。</p>
<h2 id="报错处理">报错处理</h2>
<p>将环境目录指向电脑上存储<code>network3.py</code>的目录，</p>
<p>输入<code>python</code>进入python解释器。</p>
<p>继续输入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt;<span class="keyword">import</span> network3</span><br></pre></td></tr></table></figure>
<p>在此处应该会<strong>报错</strong>。</p>
<p><code>Import Error:cannot import name downsample</code><br>
<img src="https://img-blog.csdnimg.cn/20200123215036286.JPG" alt="在这里插入图片描述"></p>
<p>因为教材比较早，代码里使用的<code>downsample</code>在现在的python中已经不再使用了，因此我们需要对代码本身做一点改动。</p>
<p>随便用一个编辑器打开<code>network3.py</code>的代码，修改其中一行，将<code>downsample</code>改为<code>pool</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#from theano.tensor.signal import downsample</span></span><br><span class="line"><span class="keyword">from</span> theano.tensor.signal <span class="keyword">import</span> pool</span><br></pre></td></tr></table></figure>
<p>代码中运用到downsample的部分也要改掉<br>
在代码中找到下面的一段</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">pooled_out = downsample.max_pool_2d(</span><br><span class="line">       input=conv_out,</span><br><span class="line">       ds=poolsize,</span><br><span class="line">       ignore_border=<span class="literal">True</span></span><br><span class="line"> )</span><br></pre></td></tr></table></figure>
<p>改成</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> pooled_out = pool.pool_2d(</span><br><span class="line">     input=conv_out,</span><br><span class="line">     ws=poolsize,</span><br><span class="line">     ignore_border=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>参考博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/moxiaobeiMM/article/details/75015408">python无法加载downsample模型问题</a></p>
<p>之后再导入network3就可以顺利进行了。</p>
<h2 id="代码运行">代码运行</h2>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"> &gt;&gt;&gt; <span class="keyword">import</span> network3</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> network3 <span class="keyword">import</span> Network</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> network3 <span class="keyword">import</span> ConvPoolLayer, FullyConnectedLayer, SoftmaxLayer</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>training_data, validation_data, test_data = network3.load_data_shared()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>mini_batch_size = <span class="number">10</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = Network([</span><br><span class="line">FullyConnectedLayer(n_in=<span class="number">784</span>, n_out=<span class="number">100</span>),</span><br><span class="line">SoftmaxLayer(n_in=<span class="number">100</span>, n_out=<span class="number">10</span>)], mini_batch_size)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.SGD(training_data, <span class="number">60</span>, mini_batch_size, <span class="number">0.1</span>,</span><br><span class="line">validation_data, test_data)</span><br></pre></td></tr></table></figure>
<p>此处我们使用的是只有一个包含100个神经元的隐藏层</p>
<p>同时使用<strong>对数似然代价函数</strong>和<strong>柔性最大值层</strong>，因为这两个方法在现在的图像分类网络中很常见。关于上面两个方法的描述，请见我之前的博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/Anastasiawangyx/article/details/102866483">改善神经网络学习的方法</a></p>
<p>最终可以达到97.83%的准确率，准确率在不同电脑上会有细微差别，大致在97.8%左右。<br>
<img src="https://img-blog.csdnimg.cn/20200123221928240.JPG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="一层卷积网络">一层卷积网络</h3>
<p>使用<strong>卷积神经网络</strong>来解决这个问题。</p>
<p>让我们从在网络开始位置的右边插⼊⼀个卷积层开始。我们将使用 5 × 5 局部感受野，跨距为 1，同时使用20 个特征映射。</p>
<p>我们也会插⼊⼀个最⼤值混合层，它⽤⼀个 2 × 2 的混合窗⼝来合并特征。所以总体的⽹络架构看起来很像上⼀节讨论的架构，但是有⼀个额外的全连接层：</p>
<p><img src="https://img-blog.csdnimg.cn/20200123223208956.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0FuYXN0YXNpYXdhbmd5eA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>
在这个架构中，我们可以把卷积和混合层看作是在学习输⼊训练图像中的局部感受野，而后面的全连接层则在⼀个更抽象的层次学习，从整个图像整合全局信息。这是⼀种常见的卷积神经网络模式。</p>
<p>在python解释器中输入下列代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = Network([</span><br><span class="line">ConvPoolLayer(image_shape=(mini_batch_size, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>),</span><br><span class="line">filter_shape=(<span class="number">20</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">poolsize=(<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">FullyConnectedLayer(n_in=<span class="number">20</span>*<span class="number">12</span>*<span class="number">12</span>, n_out=<span class="number">100</span>),</span><br><span class="line">SoftmaxLayer(n_in=<span class="number">100</span>, n_out=<span class="number">10</span>)], mini_batch_size)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.SGD(training_data, <span class="number">60</span>, mini_batch_size, <span class="number">0.1</span>,</span><br><span class="line">validation_data, test_data)</span><br></pre></td></tr></table></figure>
<p>最终达到的准确率在98.78%左右，相比之前已经得到了很大的改善。</p>
<h3 id="两层卷积网络">两层卷积网络</h3>
<p>我们试着插⼊<strong>第二个卷积–混合层</strong>。把它插在已有的卷积–混合层和全连接隐藏层之间。我们再次使用⼀个 5 × 5 局部感受野，混合 2 × 2 的区域。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = Network([</span><br><span class="line">        ConvPoolLayer(image_shape=(mini_batch_size, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), </span><br><span class="line">                      filter_shape=(<span class="number">20</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>), </span><br><span class="line">                      poolsize=(<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">        ConvPoolLayer(image_shape=(mini_batch_size, <span class="number">20</span>, <span class="number">12</span>, <span class="number">12</span>), </span><br><span class="line">                      filter_shape=(<span class="number">40</span>, <span class="number">20</span>, <span class="number">5</span>, <span class="number">5</span>), </span><br><span class="line">                      poolsize=(<span class="number">2</span>, <span class="number">2</span>)),</span><br><span class="line">        FullyConnectedLayer(n_in=<span class="number">40</span>*<span class="number">4</span>*<span class="number">4</span>, n_out=<span class="number">100</span>),</span><br><span class="line">        SoftmaxLayer(n_in=<span class="number">100</span>, n_out=<span class="number">10</span>)], mini_batch_size)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.SGD(training_data, <span class="number">60</span>, mini_batch_size, <span class="number">0.1</span>, </span><br><span class="line">            validation_data, test_data) </span><br></pre></td></tr></table></figure>
<p>这一次我们的准确率可以达到99.06%。</p>
<h3 id="修正线性单元">修正线性单元</h3>
<p>但是我们仍然可以通过改进我们的神经网络获得更好的分辨率。</p>
<p>这次我们使用修正线性单元，而不是S型激活函数。其表达式形式为:</p>
<p><code>f(z) ≡ max(0, z)</code>。</p>
<p>关于修正线性单元的信息可以参考我之前的博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/Anastasiawangyx/article/details/102866483">改善神经网络学习的方法。</a></p>
<p>同时我们加入L2规范化，规范化参数λ = 0.1。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> network3 <span class="keyword">import</span> ReLU</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = Network([</span><br><span class="line">ConvPoolLayer(image_shape=(mini_batch_size, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>),</span><br><span class="line">filter_shape=(<span class="number">20</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">poolsize=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">activation_fn=ReLU),</span><br><span class="line">ConvPoolLayer(image_shape=(mini_batch_size, <span class="number">20</span>, <span class="number">12</span>, <span class="number">12</span>),</span><br><span class="line">filter_shape=(<span class="number">40</span>, <span class="number">20</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">poolsize=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">activation_fn=ReLU),</span><br><span class="line">FullyConnectedLayer(n_in=<span class="number">40</span>*<span class="number">4</span>*<span class="number">4</span>, n_out=<span class="number">100</span>, activation_fn=ReLU),</span><br><span class="line">SoftmaxLayer(n_in=<span class="number">100</span>, n_out=<span class="number">10</span>)], mini_batch_size)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.SGD(training_data, <span class="number">60</span>, mini_batch_size, <span class="number">0.03</span>,</span><br><span class="line">validation_data, test_data, lmbda=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p>此时得到的分辨率应该为99.23%左右，相比之前又有了很大的提高。</p>
<h3 id="拓展训练数据">拓展训练数据</h3>
<p>在上面的基础上，我们以算法的形式拓展训练数据。</p>
<p>具体做法是将图像平移若干个像素，即可以得到一副新的图像。</p>
<p>我们在shell提示符中运行程序<code>expend_mnist.py</code>来实现数据的拓展。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ python expend_mnist.py</span><br></pre></td></tr></table></figure>
<p>运⾏这个程序取得 50, 000 幅 MNIST 训练图像并扩展为具有 250, 000 幅训练图像的训练集。然后我们可以使⽤这些训练图像来训练我们的网络。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>expanded_training_data, _, _ = network3.load_data_shared(</span><br><span class="line"><span class="string">&quot;../data/mnist_expanded.pkl.gz&quot;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = Network([</span><br><span class="line">ConvPoolLayer(image_shape=(mini_batch_size, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>),</span><br><span class="line">filter_shape=(<span class="number">20</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">poolsize=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">activation_fn=ReLU),</span><br><span class="line">ConvPoolLayer(image_shape=(mini_batch_size, <span class="number">20</span>, <span class="number">12</span>, <span class="number">12</span>),</span><br><span class="line">filter_shape=(<span class="number">40</span>, <span class="number">20</span>, <span class="number">5</span>, <span class="number">5</span>),</span><br><span class="line">poolsize=(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">activation_fn=ReLU),</span><br><span class="line">FullyConnectedLayer(n_in=<span class="number">40</span>*<span class="number">4</span>*<span class="number">4</span>, n_out=<span class="number">100</span>, activation_fn=ReLU),</span><br><span class="line">SoftmaxLayer(n_in=<span class="number">100</span>, n_out=<span class="number">10</span>)], mini_batch_size)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.SGD(expanded_training_data, <span class="number">60</span>, mini_batch_size, <span class="number">0.03</span>,</span><br><span class="line">validation_data, test_data, lmbda=<span class="number">0.1</span>)</span><br></pre></td></tr></table></figure>
<p>最终可以得到99.37%左右的分辨准确率。</p>
<h3 id="使用弃权的全连接层">使用弃权的全连接层</h3>
<p>在以上方法的基础上，我们再加一层全连接层，这样我们就有两个含有100个神经元的全连接层。</p>
<p>同时，将之前接触过的弃权技术运用到最终的全连接层上。</p>
<p>我们知道，弃权技术的基本思想是，在训练网络时随机的移除单独的激活值，降低网络的依赖性，有助于减轻过度拟合现象。参考博客：<a target="_blank" rel="noopener" href="https://blog.csdn.net/Anastasiawangyx/article/details/102866483">改善神经网络学习的方法。</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = Network([</span><br><span class="line">        ConvPoolLayer(image_shape=(mini_batch_size, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>), </span><br><span class="line">                      filter_shape=(<span class="number">20</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>), </span><br><span class="line">                      poolsize=(<span class="number">2</span>, <span class="number">2</span>), </span><br><span class="line">                      activation_fn=ReLU),</span><br><span class="line">        ConvPoolLayer(image_shape=(mini_batch_size, <span class="number">20</span>, <span class="number">12</span>, <span class="number">12</span>), </span><br><span class="line">                      filter_shape=(<span class="number">40</span>, <span class="number">20</span>, <span class="number">5</span>, <span class="number">5</span>), </span><br><span class="line">                      poolsize=(<span class="number">2</span>, <span class="number">2</span>), </span><br><span class="line">                      activation_fn=ReLU),</span><br><span class="line">        FullyConnectedLayer(</span><br><span class="line">            n_in=<span class="number">40</span>*<span class="number">4</span>*<span class="number">4</span>, n_out=<span class="number">1000</span>, activation_fn=ReLU, p_dropout=<span class="number">0.5</span>),</span><br><span class="line">        FullyConnectedLayer(</span><br><span class="line">            n_in=<span class="number">1000</span>, n_out=<span class="number">1000</span>, activation_fn=ReLU, p_dropout=<span class="number">0.5</span>),</span><br><span class="line">        SoftmaxLayer(n_in=<span class="number">1000</span>, n_out=<span class="number">10</span>, p_dropout=<span class="number">0.5</span>)], </span><br><span class="line">        mini_batch_size)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.SGD(expanded_training_data, <span class="number">40</span>, mini_batch_size, <span class="number">0.03</span>, </span><br><span class="line">            validation_data, test_data)</span><br></pre></td></tr></table></figure>
<p>使用弃权的全连接层，我们的神经网络的分辨率提高到了99.60%。</p>
<h3 id="使用组合网络">使用组合网络</h3>
<p>借助上面的方法，我们可以将准确率提高到99.60%左右。</p>
<p>⼀个简单的进⼀步提⾼性能的⽅法是创建几个神经网络，然后让它们投票来决定最好的分类。例如，假设我们使⽤上述的方式训练了 5 个不同的神经⽹络，每个达到了接近于 99.60% 的准确率。尽管网络都会有相似的准确率，他们很可能因为不同的随机初始化产生不同的错误。在这 5 个网络中进行⼀次投票来取得⼀个优于单个网络的分类，能进一步提高准确率。</p>
<h2 id="源代码">源代码</h2>
<p>以下是修改过的源代码，运行环境：python2.7，需要的库：<code>numpy</code>、<code>theano</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;network3.py</span></span><br><span class="line"><span class="string">~~~~~~~~~~~~~~</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">A Theano-based program for training and running simple neural</span></span><br><span class="line"><span class="string">networks.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Supports several layer types (fully connected, convolutional, max</span></span><br><span class="line"><span class="string">pooling, softmax), and activation functions (sigmoid, tanh, and</span></span><br><span class="line"><span class="string">rectified linear units, with more easily added).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">When run on a CPU, this program is much faster than network.py and</span></span><br><span class="line"><span class="string">network2.py.  However, unlike network.py and network2.py it can also</span></span><br><span class="line"><span class="string">be run on a GPU, which makes it faster still.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Because the code is based on Theano, the code is different in many</span></span><br><span class="line"><span class="string">ways from network.py and network2.py.  However, where possible I have</span></span><br><span class="line"><span class="string">tried to maintain consistency with the earlier programs.  In</span></span><br><span class="line"><span class="string">particular, the API is similar to network2.py.  Note that I have</span></span><br><span class="line"><span class="string">focused on making the code simple, easily readable, and easily</span></span><br><span class="line"><span class="string">modifiable.  It is not optimized, and omits many desirable features.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">This program incorporates ideas from the Theano documentation on</span></span><br><span class="line"><span class="string">convolutional neural nets (notably,</span></span><br><span class="line"><span class="string">http://deeplearning.net/tutorial/lenet.html ), from Misha Denil&#x27;s</span></span><br><span class="line"><span class="string">implementation of dropout (https://github.com/mdenil/dropout ), and</span></span><br><span class="line"><span class="string">from Chris Olah (http://colah.github.io ).</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Written for Theano 0.6 and 0.7, needs some changes for more recent</span></span><br><span class="line"><span class="string">versions of Theano.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### Libraries</span></span><br><span class="line"><span class="comment"># Standard library</span></span><br><span class="line"><span class="keyword">import</span> cPickle</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"></span><br><span class="line"><span class="comment"># Third-party libraries</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> theano</span><br><span class="line"><span class="keyword">import</span> theano.tensor <span class="keyword">as</span> T</span><br><span class="line"><span class="keyword">from</span> theano.tensor.nnet <span class="keyword">import</span> conv</span><br><span class="line"><span class="keyword">from</span> theano.tensor.nnet <span class="keyword">import</span> softmax</span><br><span class="line"><span class="keyword">from</span> theano.tensor <span class="keyword">import</span> shared_randomstreams</span><br><span class="line"><span class="comment">#from theano.tensor.signal import downsample</span></span><br><span class="line"><span class="keyword">from</span> theano.tensor.signal <span class="keyword">import</span> pool</span><br><span class="line"></span><br><span class="line"><span class="comment"># Activation functions for neurons</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">linear</span>(<span class="params">z</span>):</span> <span class="keyword">return</span> z</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ReLU</span>(<span class="params">z</span>):</span> <span class="keyword">return</span> T.maximum(<span class="number">0.0</span>, z)</span><br><span class="line"><span class="keyword">from</span> theano.tensor.nnet <span class="keyword">import</span> sigmoid</span><br><span class="line"><span class="keyword">from</span> theano.tensor <span class="keyword">import</span> tanh</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### Constants</span></span><br><span class="line">GPU = <span class="literal">True</span></span><br><span class="line"><span class="keyword">if</span> GPU:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;Trying to run under a GPU.  If this is not desired, then modify &quot;</span>+\</span><br><span class="line">        <span class="string">&quot;network3.py\nto set the GPU flag to False.&quot;</span></span><br><span class="line">    <span class="keyword">try</span>: theano.config.device = <span class="string">&#x27;gpu&#x27;</span></span><br><span class="line">    <span class="keyword">except</span>: <span class="keyword">pass</span> <span class="comment"># it&#x27;s already set</span></span><br><span class="line">    theano.config.floatX = <span class="string">&#x27;float32&#x27;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">&quot;Running with a CPU.  If this is not desired, then the modify &quot;</span>+\</span><br><span class="line">        <span class="string">&quot;network3.py to set\nthe GPU flag to True.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#### Load the MNIST data</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data_shared</span>(<span class="params">filename=<span class="string">&quot;../data/mnist.pkl.gz&quot;</span></span>):</span></span><br><span class="line">    f = gzip.open(filename, <span class="string">&#x27;rb&#x27;</span>)</span><br><span class="line">    training_data, validation_data, test_data = cPickle.load(f)</span><br><span class="line">    f.close()</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">shared</span>(<span class="params">data</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Place the data into shared variables.  This allows Theano to copy</span></span><br><span class="line"><span class="string">        the data to the GPU, if one is available.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        shared_x = theano.shared(</span><br><span class="line">            np.asarray(data[<span class="number">0</span>], dtype=theano.config.floatX), borrow=<span class="literal">True</span>)</span><br><span class="line">        shared_y = theano.shared(</span><br><span class="line">            np.asarray(data[<span class="number">1</span>], dtype=theano.config.floatX), borrow=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> shared_x, T.cast(shared_y, <span class="string">&quot;int32&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> [shared(training_data), shared(validation_data), shared(test_data)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#### Main class used to construct and train networks</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Network</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, layers, mini_batch_size</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Takes a list of `layers`, describing the network architecture, and</span></span><br><span class="line"><span class="string">        a value for the `mini_batch_size` to be used during training</span></span><br><span class="line"><span class="string">        by stochastic gradient descent.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.layers = layers</span><br><span class="line">        self.mini_batch_size = mini_batch_size</span><br><span class="line">        self.params = [param <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers <span class="keyword">for</span> param <span class="keyword">in</span> layer.params]</span><br><span class="line">        self.x = T.matrix(<span class="string">&quot;x&quot;</span>)</span><br><span class="line">        self.y = T.ivector(<span class="string">&quot;y&quot;</span>)</span><br><span class="line">        init_layer = self.layers[<span class="number">0</span>]</span><br><span class="line">        init_layer.set_inpt(self.x, self.x, self.mini_batch_size)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> xrange(<span class="number">1</span>, len(self.layers)):</span><br><span class="line">            prev_layer, layer  = self.layers[j<span class="number">-1</span>], self.layers[j]</span><br><span class="line">            layer.set_inpt(</span><br><span class="line">                prev_layer.output, prev_layer.output_dropout, self.mini_batch_size)</span><br><span class="line">        self.output = self.layers[<span class="number">-1</span>].output</span><br><span class="line">        self.output_dropout = self.layers[<span class="number">-1</span>].output_dropout</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">SGD</span>(<span class="params">self, training_data, epochs, mini_batch_size, eta,</span></span></span><br><span class="line"><span class="function"><span class="params">            validation_data, test_data, lmbda=<span class="number">0.0</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;Train the network using mini-batch stochastic gradient descent.&quot;&quot;&quot;</span></span><br><span class="line">        training_x, training_y = training_data</span><br><span class="line">        validation_x, validation_y = validation_data</span><br><span class="line">        test_x, test_y = test_data</span><br><span class="line"></span><br><span class="line">        <span class="comment"># compute number of minibatches for training, validation and testing</span></span><br><span class="line">        num_training_batches = size(training_data)/mini_batch_size</span><br><span class="line">        num_validation_batches = size(validation_data)/mini_batch_size</span><br><span class="line">        num_test_batches = size(test_data)/mini_batch_size</span><br><span class="line"></span><br><span class="line">        <span class="comment"># define the (regularized) cost function, symbolic gradients, and updates</span></span><br><span class="line">        l2_norm_squared = sum([(layer.w**<span class="number">2</span>).sum() <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers])</span><br><span class="line">        cost = self.layers[<span class="number">-1</span>].cost(self)+\</span><br><span class="line">               <span class="number">0.5</span>*lmbda*l2_norm_squared/num_training_batches</span><br><span class="line">        grads = T.grad(cost, self.params)</span><br><span class="line">        updates = [(param, param-eta*grad)</span><br><span class="line">                   <span class="keyword">for</span> param, grad <span class="keyword">in</span> zip(self.params, grads)]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># define functions to train a mini-batch, and to compute the</span></span><br><span class="line">        <span class="comment"># accuracy in validation and test mini-batches.</span></span><br><span class="line">        i = T.lscalar() <span class="comment"># mini-batch index</span></span><br><span class="line">        train_mb = theano.function(</span><br><span class="line">            [i], cost, updates=updates,</span><br><span class="line">            givens=&#123;</span><br><span class="line">                self.x:</span><br><span class="line">                training_x[i*self.mini_batch_size: (i+<span class="number">1</span>)*self.mini_batch_size],</span><br><span class="line">                self.y:</span><br><span class="line">                training_y[i*self.mini_batch_size: (i+<span class="number">1</span>)*self.mini_batch_size]</span><br><span class="line">            &#125;)</span><br><span class="line">        validate_mb_accuracy = theano.function(</span><br><span class="line">            [i], self.layers[<span class="number">-1</span>].accuracy(self.y),</span><br><span class="line">            givens=&#123;</span><br><span class="line">                self.x:</span><br><span class="line">                validation_x[i*self.mini_batch_size: (i+<span class="number">1</span>)*self.mini_batch_size],</span><br><span class="line">                self.y:</span><br><span class="line">                validation_y[i*self.mini_batch_size: (i+<span class="number">1</span>)*self.mini_batch_size]</span><br><span class="line">            &#125;)</span><br><span class="line">        test_mb_accuracy = theano.function(</span><br><span class="line">            [i], self.layers[<span class="number">-1</span>].accuracy(self.y),</span><br><span class="line">            givens=&#123;</span><br><span class="line">                self.x:</span><br><span class="line">                test_x[i*self.mini_batch_size: (i+<span class="number">1</span>)*self.mini_batch_size],</span><br><span class="line">                self.y:</span><br><span class="line">                test_y[i*self.mini_batch_size: (i+<span class="number">1</span>)*self.mini_batch_size]</span><br><span class="line">            &#125;)</span><br><span class="line">        self.test_mb_predictions = theano.function(</span><br><span class="line">            [i], self.layers[<span class="number">-1</span>].y_out,</span><br><span class="line">            givens=&#123;</span><br><span class="line">                self.x:</span><br><span class="line">                test_x[i*self.mini_batch_size: (i+<span class="number">1</span>)*self.mini_batch_size]</span><br><span class="line">            &#125;)</span><br><span class="line">        <span class="comment"># Do the actual training</span></span><br><span class="line">        best_validation_accuracy = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> xrange(epochs):</span><br><span class="line">            <span class="keyword">for</span> minibatch_index <span class="keyword">in</span> xrange(num_training_batches):</span><br><span class="line">                iteration = num_training_batches*epoch+minibatch_index</span><br><span class="line">                <span class="keyword">if</span> iteration % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                    print(<span class="string">&quot;Training mini-batch number &#123;0&#125;&quot;</span>.format(iteration))</span><br><span class="line">                cost_ij = train_mb(minibatch_index)</span><br><span class="line">                <span class="keyword">if</span> (iteration+<span class="number">1</span>) % num_training_batches == <span class="number">0</span>:</span><br><span class="line">                    validation_accuracy = np.mean(</span><br><span class="line">                        [validate_mb_accuracy(j) <span class="keyword">for</span> j <span class="keyword">in</span> xrange(num_validation_batches)])</span><br><span class="line">                    print(<span class="string">&quot;Epoch &#123;0&#125;: validation accuracy &#123;1:.2%&#125;&quot;</span>.format(</span><br><span class="line">                        epoch, validation_accuracy))</span><br><span class="line">                    <span class="keyword">if</span> validation_accuracy &gt;= best_validation_accuracy:</span><br><span class="line">                        print(<span class="string">&quot;This is the best validation accuracy to date.&quot;</span>)</span><br><span class="line">                        best_validation_accuracy = validation_accuracy</span><br><span class="line">                        best_iteration = iteration</span><br><span class="line">                        <span class="keyword">if</span> test_data:</span><br><span class="line">                            test_accuracy = np.mean(</span><br><span class="line">                                [test_mb_accuracy(j) <span class="keyword">for</span> j <span class="keyword">in</span> xrange(num_test_batches)])</span><br><span class="line">                            print(<span class="string">&#x27;The corresponding test accuracy is &#123;0:.2%&#125;&#x27;</span>.format(</span><br><span class="line">                                test_accuracy))</span><br><span class="line">        print(<span class="string">&quot;Finished training network.&quot;</span>)</span><br><span class="line">        print(<span class="string">&quot;Best validation accuracy of &#123;0:.2%&#125; obtained at iteration &#123;1&#125;&quot;</span>.format(</span><br><span class="line">            best_validation_accuracy, best_iteration))</span><br><span class="line">        print(<span class="string">&quot;Corresponding test accuracy of &#123;0:.2%&#125;&quot;</span>.format(test_accuracy))</span><br><span class="line"></span><br><span class="line"><span class="comment">#### Define layer types</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvPoolLayer</span>(<span class="params">object</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Used to create a combination of a convolutional and a max-pooling</span></span><br><span class="line"><span class="string">    layer.  A more sophisticated implementation would separate the</span></span><br><span class="line"><span class="string">    two, but for our purposes we&#x27;ll always use them together, and it</span></span><br><span class="line"><span class="string">    simplifies the code, so it makes sense to combine them.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, filter_shape, image_shape, poolsize=(<span class="params"><span class="number">2</span>, <span class="number">2</span></span>),</span></span></span><br><span class="line"><span class="function"><span class="params">                 activation_fn=sigmoid</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;`filter_shape` is a tuple of length 4, whose entries are the number</span></span><br><span class="line"><span class="string">        of filters, the number of input feature maps, the filter height, and the</span></span><br><span class="line"><span class="string">        filter width.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `image_shape` is a tuple of length 4, whose entries are the</span></span><br><span class="line"><span class="string">        mini-batch size, the number of input feature maps, the image</span></span><br><span class="line"><span class="string">        height, and the image width.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        `poolsize` is a tuple of length 2, whose entries are the y and</span></span><br><span class="line"><span class="string">        x pooling sizes.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.filter_shape = filter_shape</span><br><span class="line">        self.image_shape = image_shape</span><br><span class="line">        self.poolsize = poolsize</span><br><span class="line">        self.activation_fn=activation_fn</span><br><span class="line">        <span class="comment"># initialize weights and biases</span></span><br><span class="line">        n_out = (filter_shape[<span class="number">0</span>]*np.prod(filter_shape[<span class="number">2</span>:])/np.prod(poolsize))</span><br><span class="line">        self.w = theano.shared(</span><br><span class="line">            np.asarray(</span><br><span class="line">                np.random.normal(loc=<span class="number">0</span>, scale=np.sqrt(<span class="number">1.0</span>/n_out), size=filter_shape),</span><br><span class="line">                dtype=theano.config.floatX),</span><br><span class="line">            borrow=<span class="literal">True</span>)</span><br><span class="line">        self.b = theano.shared(</span><br><span class="line">            np.asarray(</span><br><span class="line">                np.random.normal(loc=<span class="number">0</span>, scale=<span class="number">1.0</span>, size=(filter_shape[<span class="number">0</span>],)),</span><br><span class="line">                dtype=theano.config.floatX),</span><br><span class="line">            borrow=<span class="literal">True</span>)</span><br><span class="line">        self.params = [self.w, self.b]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_inpt</span>(<span class="params">self, inpt, inpt_dropout, mini_batch_size</span>):</span></span><br><span class="line">        self.inpt = inpt.reshape(self.image_shape)</span><br><span class="line">        conv_out = conv.conv2d(</span><br><span class="line">            input=self.inpt, filters=self.w, filter_shape=self.filter_shape,</span><br><span class="line">            image_shape=self.image_shape)</span><br><span class="line">        pooled_out = pool.pool_2d(</span><br><span class="line">            input=conv_out, ws=self.poolsize, ignore_border=<span class="literal">True</span>)</span><br><span class="line">        self.output = self.activation_fn(</span><br><span class="line">            pooled_out + self.b.dimshuffle(<span class="string">&#x27;x&#x27;</span>, <span class="number">0</span>, <span class="string">&#x27;x&#x27;</span>, <span class="string">&#x27;x&#x27;</span>))</span><br><span class="line">        self.output_dropout = self.output <span class="comment"># no dropout in the convolutional layers</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FullyConnectedLayer</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_in, n_out, activation_fn=sigmoid, p_dropout=<span class="number">0.0</span></span>):</span></span><br><span class="line">        self.n_in = n_in</span><br><span class="line">        self.n_out = n_out</span><br><span class="line">        self.activation_fn = activation_fn</span><br><span class="line">        self.p_dropout = p_dropout</span><br><span class="line">        <span class="comment"># Initialize weights and biases</span></span><br><span class="line">        self.w = theano.shared(</span><br><span class="line">            np.asarray(</span><br><span class="line">                np.random.normal(</span><br><span class="line">                    loc=<span class="number">0.0</span>, scale=np.sqrt(<span class="number">1.0</span>/n_out), size=(n_in, n_out)),</span><br><span class="line">                dtype=theano.config.floatX),</span><br><span class="line">            name=<span class="string">&#x27;w&#x27;</span>, borrow=<span class="literal">True</span>)</span><br><span class="line">        self.b = theano.shared(</span><br><span class="line">            np.asarray(np.random.normal(loc=<span class="number">0.0</span>, scale=<span class="number">1.0</span>, size=(n_out,)),</span><br><span class="line">                       dtype=theano.config.floatX),</span><br><span class="line">            name=<span class="string">&#x27;b&#x27;</span>, borrow=<span class="literal">True</span>)</span><br><span class="line">        self.params = [self.w, self.b]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_inpt</span>(<span class="params">self, inpt, inpt_dropout, mini_batch_size</span>):</span></span><br><span class="line">        self.inpt = inpt.reshape((mini_batch_size, self.n_in))</span><br><span class="line">        self.output = self.activation_fn(</span><br><span class="line">            (<span class="number">1</span>-self.p_dropout)*T.dot(self.inpt, self.w) + self.b)</span><br><span class="line">        self.y_out = T.argmax(self.output, axis=<span class="number">1</span>)</span><br><span class="line">        self.inpt_dropout = dropout_layer(</span><br><span class="line">            inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout)</span><br><span class="line">        self.output_dropout = self.activation_fn(</span><br><span class="line">            T.dot(self.inpt_dropout, self.w) + self.b)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">self, y</span>):</span></span><br><span class="line">        <span class="string">&quot;Return the accuracy for the mini-batch.&quot;</span></span><br><span class="line">        <span class="keyword">return</span> T.mean(T.eq(y, self.y_out))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SoftmaxLayer</span>(<span class="params">object</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, n_in, n_out, p_dropout=<span class="number">0.0</span></span>):</span></span><br><span class="line">        self.n_in = n_in</span><br><span class="line">        self.n_out = n_out</span><br><span class="line">        self.p_dropout = p_dropout</span><br><span class="line">        <span class="comment"># Initialize weights and biases</span></span><br><span class="line">        self.w = theano.shared(</span><br><span class="line">            np.zeros((n_in, n_out), dtype=theano.config.floatX),</span><br><span class="line">            name=<span class="string">&#x27;w&#x27;</span>, borrow=<span class="literal">True</span>)</span><br><span class="line">        self.b = theano.shared(</span><br><span class="line">            np.zeros((n_out,), dtype=theano.config.floatX),</span><br><span class="line">            name=<span class="string">&#x27;b&#x27;</span>, borrow=<span class="literal">True</span>)</span><br><span class="line">        self.params = [self.w, self.b]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">set_inpt</span>(<span class="params">self, inpt, inpt_dropout, mini_batch_size</span>):</span></span><br><span class="line">        self.inpt = inpt.reshape((mini_batch_size, self.n_in))</span><br><span class="line">        self.output = softmax((<span class="number">1</span>-self.p_dropout)*T.dot(self.inpt, self.w) + self.b)</span><br><span class="line">        self.y_out = T.argmax(self.output, axis=<span class="number">1</span>)</span><br><span class="line">        self.inpt_dropout = dropout_layer(</span><br><span class="line">            inpt_dropout.reshape((mini_batch_size, self.n_in)), self.p_dropout)</span><br><span class="line">        self.output_dropout = softmax(T.dot(self.inpt_dropout, self.w) + self.b)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cost</span>(<span class="params">self, net</span>):</span></span><br><span class="line">        <span class="string">&quot;Return the log-likelihood cost.&quot;</span></span><br><span class="line">        <span class="keyword">return</span> -T.mean(T.log(self.output_dropout)[T.arange(net.y.shape[<span class="number">0</span>]), net.y])</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">accuracy</span>(<span class="params">self, y</span>):</span></span><br><span class="line">        <span class="string">&quot;Return the accuracy for the mini-batch.&quot;</span></span><br><span class="line">        <span class="keyword">return</span> T.mean(T.eq(y, self.y_out))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#### Miscellanea</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">size</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="string">&quot;Return the size of the dataset `data`.&quot;</span></span><br><span class="line">    <span class="keyword">return</span> data[<span class="number">0</span>].get_value(borrow=<span class="literal">True</span>).shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dropout_layer</span>(<span class="params">layer, p_dropout</span>):</span></span><br><span class="line">    srng = shared_randomstreams.RandomStreams(</span><br><span class="line">        np.random.RandomState(<span class="number">0</span>).randint(<span class="number">999999</span>))</span><br><span class="line">    mask = srng.binomial(n=<span class="number">1</span>, p=<span class="number">1</span>-p_dropout, size=layer.shape)</span><br><span class="line">    <span class="keyword">return</span> layer*T.cast(mask, theano.config.floatX)</span><br></pre></td></tr></table></figure>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Anastasia</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2020/09/11/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN+%E8%AF%86%E5%88%AB%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97MNIST%EF%BC%88%E9%99%84%E4%BB%A3%E7%A0%81%EF%BC%89%E2%80%94%E2%80%94AI%E5%85%A5%E9%97%A8/">http://example.com/2020/09/11/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CCNN+%E8%AF%86%E5%88%AB%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97MNIST%EF%BC%88%E9%99%84%E4%BB%A3%E7%A0%81%EF%BC%89%E2%80%94%E2%80%94AI%E5%85%A5%E9%97%A8/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">Ana's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/network/">network</a><a class="post-meta__tags" href="/tags/python/">python</a></div><div class="post_share"><div class="social-share" data-image="https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-fc6b5bc5ed17621fa52acf7a19b2e379_1440w.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/09/11/%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%BA%E4%BD%95%E5%BE%88%E9%9A%BE%E8%AE%AD%E7%BB%83%EF%BC%9F%E2%80%94%E2%80%94AI%E5%85%A5%E9%97%A8/"><img class="prev-cover" src="https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-fc6b5bc5ed17621fa52acf7a19b2e379_1440w.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">神经网络为何很难训练？</div></div></a></div><div class="next-post pull-right"><a href="/2020/09/11/%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%AE%97%E6%B3%95%EF%BC%88backpropagation%EF%BC%89%E8%AE%A1%E7%AE%97%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%EF%BC%88SGD%EF%BC%89%E2%80%94%E2%80%94AI%E5%85%A5%E9%97%A8/"><img class="next-cover" src="https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-fc6b5bc5ed17621fa52acf7a19b2e379_1440w.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">反向传播算法(backpropagation)计算梯度下降(SGD)详解</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2020/09/10/2020-09-10-手写数字识别MNIST（python3）/" title="手写数字识别MNIST（python3）"><img class="cover" src="https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-834cdc1e1f29e1f92ec25185fe1e964e_1440w.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-09-10</div><div class="title">手写数字识别MNIST（python3）</div></div></a></div><div><a href="/2020/09/11/反向传播算法（backpropagation）计算梯度下降（SGD）——AI入门/" title="反向传播算法(backpropagation)计算梯度下降(SGD)详解"><img class="cover" src="https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-fc6b5bc5ed17621fa52acf7a19b2e379_1440w.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-09-11</div><div class="title">反向传播算法(backpropagation)计算梯度下降(SGD)详解</div></div></a></div><div><a href="/2020/09/11/深度神经网络为何很难训练？——AI入门/" title="神经网络为何很难训练？"><img class="cover" src="https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-fc6b5bc5ed17621fa52acf7a19b2e379_1440w.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-09-11</div><div class="title">神经网络为何很难训练？</div></div></a></div><div><a href="/2020/09/11/神经网络可以计算任何函数的可视化证明——AI入门/" title="神经网络可以计算任何函数的可视化证明"><img class="cover" src="https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-fc6b5bc5ed17621fa52acf7a19b2e379_1440w.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-09-11</div><div class="title">神经网络可以计算任何函数的可视化证明</div></div></a></div><div><a href="/2020/09/11/2020-09-11-改善神经网络的学习方法（交叉熵函数，过度拟合，规范化，初始化权重）/" title="改善神经网络的学习方法（交叉熵函数，过度拟合，规范化，初始化权重）"><img class="cover" src="https://mdimage001.oss-cn-beijing.aliyuncs.com/img/v2-fc6b5bc5ed17621fa52acf7a19b2e379_1440w.jpg"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-09-11</div><div class="title">改善神经网络的学习方法（交叉熵函数，过度拟合，规范化，初始化权重）</div></div></a></div></div></div></article></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Anastasia</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">hello stranger</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    loader: {
      source: {
        '[tex]/amsCd': '[tex]/amscd'
      }
    },
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        addClass: [200,() => {
          document.querySelectorAll('mjx-container:not([display=\'true\']').forEach( node => {
            const target = node.parentNode
            if (!target.classList.contains('has-jax')) {
              target.classList.add('mathjax-overflow')
            }
          })
        }, '', false]
      }
    }
  }
  
  var script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><canvas class="fireworks" mobile="false"></canvas><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/fireworks.min.js"></script><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script></div></body></html>